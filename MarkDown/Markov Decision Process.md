# Markov Decision Process

## Markov chain

contains two components: initial distribution & transition matrix	